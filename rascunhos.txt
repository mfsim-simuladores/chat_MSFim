import json
import os
from dotenv import load_dotenv
import google.generativeai as genai
from core.embedding_manager import EmbeddingManager
from core.learning_manager import learning_manager
from core.knowledge_manager import KnowledgeManager
from core.conversation_state import conversation_state

# ============================================================
# üîß CONFIGURA√á√ÉO INICIAL
# ============================================================
load_dotenv()

knowledge_path = r"D:\mfsim_assistente\data\knowledge.json"
PENDING_PATH = r"D:\mfsim_assistente\data\pending_learning.json"

embedding_manager = EmbeddingManager()
learning_manager = learning_manager(PENDING_PATH)
knowledge_manager = KnowledgeManager(knowledge_path)

API_KEY = os.getenv("GOOGLE_API_KEY")
if API_KEY:
    genai.configure(api_key=API_KEY)
else:
    print("‚ö†Ô∏è GOOGLE_API_KEY n√£o encontrada ‚Äî Gemini em modo offline.")

CONVERSAS_ATIVAS = {}

# ============================================================
# ü§ñ CONECTOR GEMINI
# ============================================================
class GeminiConnector:
    @staticmethod
    def responder(prompt: str) -> str | None:
        try:
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(prompt)
            if hasattr(response, "text") and response.text:
                return response.text.strip()
            return None
        except Exception as e:
            print(f"[Gemini] Erro: {e}")
            return None

# ============================================================
# üß† INTERPRETADOR PRINCIPAL
# ============================================================
class AIInterpreter:

    # --------------------------------------------------------
    # Detector de confirma√ß√£o natural
    # --------------------------------------------------------
    @staticmethod
    def eh_confirmacao(texto: str):
        if not texto:
            return False
        texto = texto.lower()

        afirmativas = [
            "sim", "claro", "ok", "pode", "pode ir", "vai", "continua",
            "continue", "prossiga", "concordo", "perfeito", "isso mesmo",
            "pode continuar", "vamos", "manda ver", "faz isso", "pode fazer"
        ]
        return any(a in texto for a in afirmativas)

    # --------------------------------------------------------
    @staticmethod
    def interpret(user_input: str, conversa_id: str = "default"):

        # Caso o wizard j√° esteja ativo, o interpretador n√£o interfere
        if conversation_state.get("mode") == "wizard":
            return None

        try:
            user_input = user_input.strip().lower()

            # -------- 1: SE FOR CONFIRMA√á√ÉO, RETORNA "CONFIRMAR" -------
            if AIInterpreter.eh_confirmacao(user_input):
                print("[AIInterpreter] ‚úîÔ∏è Confirma√ß√£o detectada")
                return "CONFIRMAR"

            contexto = CONVERSAS_ATIVAS.get(conversa_id, [])
            contexto.append({"role": "user", "text": user_input})

            # =====================================================
            # 2Ô∏è‚É£ Busca exata ou parcial no knowledge.json
            # =====================================================
            if os.path.exists(knowledge_path):
                with open(knowledge_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                for cat in data:
                    for item in cat.get("Items", []):
                        pergunta = item.get("Question", "").lower().strip()
                        acao = item.get("Action", "").strip()

                        # exato ou parcial (fuzzy leve)
                        if user_input == pergunta or pergunta in user_input or user_input in pergunta:
                            print(f"[AIInterpreter] üéØ A√ß√£o encontrada localmente: {acao}")
                            contexto.append({"role": "assistant", "text": acao})
                            CONVERSAS_ATIVAS[conversa_id] = contexto[-10:]
                            return acao

            # =====================================================
            # 3Ô∏è‚É£ Busca sem√¢ntica (embeddings)
            # =====================================================
            result = embedding_manager.buscar_semelhante(user_input)
            if result:
                acao = result.get("Action")
                print(f"[AIInterpreter] üîé A√ß√£o sem√¢ntica sugerida: {acao}")
                contexto.append({"role": "assistant", "text": acao})
                CONVERSAS_ATIVAS[conversa_id] = contexto[-10:]
                return acao

            # =====================================================
            # 4Ô∏è‚É£ Fallback com Gemini
            # =====================================================
            prompt = (
                "Voc√™ √© o assistente t√©cnico da MFSim. "
                "Responda de forma t√©cnica, direta e profissional:\n\n"
            )
            for m in contexto[-8:]:
                role = "Usu√°rio" if m["role"] == "user" else "Assistente"
                prompt += f"{role}: {m['text']}\n"
            prompt += "Assistente:"

            resposta = GeminiConnector.responder(prompt)
            if resposta:
                print(f"[AIInterpreter] üí¨ Resposta gerada via Gemini.")
                contexto.append({"role": "assistant", "text": resposta})
                CONVERSAS_ATIVAS[conversa_id] = contexto[-10:]
                learning_manager.registrar_instrucao(
                    pergunta=user_input, acao=None, fonte="gemini", resposta=resposta
                )
                return {"mensagem": resposta}

            # =====================================================
            # 5Ô∏è‚É£ Fallback final ‚Üí aprendizado novo
            # =====================================================
            print("[AIInterpreter] üß© Nenhuma correspond√™ncia ‚Äî registrando aprendizado novo.")
            learning_manager.registrar_instrucao(user_input)
            return {"mensagem": "üß© Nova instru√ß√£o aprendida. Ser√° revisada."}

        except Exception as e:
            print(f"[AIInterpreter] ‚ùå Erro: {e}")
            return {"mensagem": "‚ùå Erro interno."}


